---
sidebar_position: 3
sidebar_label: ‚öñÔ∏è Load Balancer NGINX pour K3s
---

# ‚öñÔ∏è Load Balancer NGINX pour Kubernetes

Guide pour configurer NGINX comme load balancer pour votre cluster K3s, g√©rant √† la fois l'API Kubernetes et le trafic applicatif.

## üéØ Objectif

Mettre en place un load balancer NGINX pour :
- **R√©partir le trafic** vers les serveurs K3s
- **Assurer la haute disponibilit√©** de l'API Kubernetes
- **G√©rer le routage** HTTP/HTTPS des applications

## üì¶ Installation

```bash title="Installation NGINX"
sudo apt update
sudo apt install nginx
```

:::tip V√©rification

V√©rifiez que NGINX est d√©marr√© :
```bash
sudo systemctl status nginx
```

:::

## ‚öôÔ∏è Configuration Load Balancer

### √âdition du fichier principal

```bash title="√âdition de la configuration NGINX"
sudo nano /etc/nginx/nginx.conf
```

### Configuration compl√®te

```nginx title="/etc/nginx/nginx.conf"
user www-data;
worker_processes auto;
pid /run/nginx.pid;
include /etc/nginx/modules-enabled/*.conf;

events {
    worker_connections 8192;
    # multi_accept on;
}

# Configuration Stream pour le load balancing
stream {
    # Pool de serveurs K3s pour l'API Kubernetes
    upstream k3s_servers {
        server 192.168.1.121:6443;  # Serveur K3s 1
        server 192.168.1.141:6443;  # Serveur K3s 2
        server 192.168.1.146:6443;  # Serveur K3s 3
    }

    # Pool pour services TCP personnalis√©s
    upstream tcp_backend {
        server 192.168.1.121:30053;
        server 192.168.1.141:30053;
        server 192.168.1.146:30053;
    }

    # Pool pour services UDP personnalis√©s
    upstream udp_backend {
        server 192.168.1.121:30054;
        server 192.168.1.141:30054;
        server 192.168.1.146:30054;
    }

    # Load balancer pour l'API Kubernetes (port 6443)
    server {
        listen 6443;
        proxy_pass k3s_servers;
        proxy_timeout 10s;
        proxy_connect_timeout 5s;
    }

    # Load balancer TCP personnalis√©
    server {
        listen 43;
        proxy_pass tcp_backend;
        proxy_timeout 1s;
        proxy_connect_timeout 1s;
    }

    # Load balancer UDP personnalis√©
    server {
        listen 43 udp;
        proxy_pass udp_backend;
        proxy_timeout 1s;
        proxy_responses 1;
    }
}

# Configuration HTTP standard (√† conserver)
http {
    # ... configuration HTTP existante ...
}
```

:::warning Adresses IP

Remplacez les adresses IP par celles de vos serveurs K3s r√©els.

:::

## üåê Configuration du trafic HTTP/HTTPS

### √âdition du site par d√©faut

```bash title="Configuration du site par d√©faut"
sudo nano /etc/nginx/sites-available/default
```

### Routage vers Ingress Controller

```nginx title="/etc/nginx/sites-available/default"
# Serveur HTTP (port 80)
server {
    listen 80;
    server_name _;
    
    location / {
        proxy_pass http://192.168.1.121;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# Serveur HTTPS (port 443)
server {
    listen 443;
    server_name _;
    
    location / {
        proxy_pass https://192.168.1.121;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Configuration SSL proxy
        proxy_ssl_verify off;
    }
}
```

:::note Ingress Controller

Cette configuration suppose que votre Ingress Controller (Traefik, Nginx-Ingress, etc.) √©coute sur le port 80/443 des n≈ìuds K3s.

:::

## üîß Gestion du service

### V√©rification de la configuration

```bash title="Test de la configuration"
sudo nginx -t
```

### Red√©marrage du service

```bash title="Red√©marrage NGINX"
sudo systemctl restart nginx
```

### Activation au d√©marrage

```bash title="Activation automatique"
sudo systemctl enable nginx
```

## ‚úÖ V√©rification du fonctionnement

### Test de l'API Kubernetes

```bash title="Test de l'API via le load balancer"
curl -k https://192.168.1.110:6443/version
```

:::tip R√©sultat attendu

Vous devriez recevoir une r√©ponse JSON avec la version de Kubernetes.

:::

### Test du trafic HTTP

```bash title="Test HTTP"
curl http://192.168.1.110
```

## üìä Monitoring et logs

### Consultation des logs

```bash title="Logs NGINX"
sudo tail -f /var/log/nginx/access.log
sudo tail -f /var/log/nginx/error.log
```

### Statistiques en temps r√©el

```bash title="Monitoring des connexions"
sudo netstat -tlnp | grep nginx
```

## üõ†Ô∏è Configuration avanc√©e

### Health checks

```nginx title="Configuration avec health checks"
upstream k3s_servers {
    server 192.168.1.121:6443 max_fails=3 fail_timeout=30s;
    server 192.168.1.141:6443 max_fails=3 fail_timeout=30s;
    server 192.168.1.146:6443 max_fails=3 fail_timeout=30s;
}
```

### Load balancing par IP

```nginx title="Persistance de session par IP"
upstream k3s_servers {
    ip_hash;
    server 192.168.1.121:6443;
    server 192.168.1.141:6443;
    server 192.168.1.146:6443;
}
```

:::info M√©thodes de load balancing

- **round-robin** (d√©faut) : R√©partition circulaire
- **ip_hash** : Persistance par IP client
- **least_conn** : Serveur avec le moins de connexions

:::

## üö® D√©pannage

### Probl√®mes courants

<details>
<summary>Erreur "Connection refused"</summary>

**Causes possibles :**
- Serveur K3s arr√™t√©
- Mauvaise configuration IP
- Firewall bloquant

**Solution :**
1. V√©rifiez l'√©tat des serveurs K3s
2. Testez la connectivit√© r√©seau
3. V√©rifiez les r√®gles firewall
</details>

<details>
<summary>Timeouts fr√©quents</summary>

**Causes possibles :**
- Timeout trop court
- Charge trop √©lev√©e
- Probl√®me r√©seau

**Solution :**
1. Augmentez les timeouts
2. Ajoutez des serveurs au pool
3. V√©rifiez la latence r√©seau
</details>

## üìã Checklist de validation

- [ ] **Installation** : NGINX install√© et d√©marr√©
- [ ] **Configuration** : Fichiers de configuration cr√©√©s
- [ ] **Syntaxe** : Configuration test√©e avec `nginx -t`
- [ ] **Service** : NGINX red√©marr√© et activ√©
- [ ] **API K3s** : Accessible via le load balancer
- [ ] **HTTP/HTTPS** : Trafic rout√© vers les applications
- [ ] **Logs** : Pas d'erreurs dans les logs

:::tip Haute disponibilit√©

Pour une vraie haute disponibilit√©, d√©ployez plusieurs instances de ce load balancer avec un VIP (Virtual IP) g√©r√© par keepalived ou HAProxy.

:::

## üîó Articles connexes

- [Cr√©ation du cluster K3s](./creation-du-cluster.md)
- [Installation n≈ìud K3s](./installation-server-node-k3s.md)